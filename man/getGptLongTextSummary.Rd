% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/getGptLongTextSummary.R
\name{getGptLongTextSummary}
\alias{getGptLongTextSummary}
\title{Generate GPT Summary for Long Text with Automatic Chunking}
\usage{
getGptLongTextSummary(
  text.vec,
  gpt.token,
  gpt.base.url = "https://api.openai.com",
  gpt.model = "gpt-4o-mini",
  system.prompt.stage1,
  user.prompt.stage1 = "Please summarize the following events{period_context}: {text}",
  system.prompt.stage2,
  user.prompt.stage2 =
    "Please provide a consolidated summary of these summaries{period_context}: {text}",
  period.label = NULL,
  max.input.tokens = 120000,
  gpt.temperature = 0,
  gpt.max.output.tokens = 2048,
  token.multiplier = 1.3,
  timeout = 120,
  max.retries = 3
)
}
\arguments{
\item{text.vec}{Character vector containing text entries to summarize}

\item{gpt.token}{Character string containing the API authentication token}

\item{gpt.base.url}{Character string for the GPT API base URL
(default: "https://api.openai.com")}

\item{gpt.model}{Character string specifying the GPT model to use
(default: "gpt-4o-mini")}

\item{system.prompt.stage1}{Character string containing the system prompt
for chunk summarization}

\item{user.prompt.stage1}{Character string containing the user prompt
template for chunk summarization (default: "Please summarize the following
events: {text}")}

\item{system.prompt.stage2}{Character string containing the system prompt
for final consolidation}

\item{user.prompt.stage2}{Character string containing the user prompt
template for final consolidation}

\item{period.label}{Character string providing temporal context for the
summary (optional, default: NULL)}

\item{max.input.tokens}{Numeric value for maximum input tokens per API call
(default: 120000)}

\item{gpt.temperature}{Numeric value for GPT temperature parameter
(default: 0)}

\item{gpt.max.output.tokens}{Numeric value for maximum output tokens from
GPT (default: 2048)}

\item{token.multiplier}{Numeric multiplier for converting word count to
estimated tokens (default: 1.3)}

\item{timeout}{Numeric. Request timeout in seconds (default: 120)}

\item{max.retries}{Integer. Maximum retry attempts (default: 3)}
}
\value{
List containing:
  \itemize{
    \item \code{final.summary} - Character string with the final consolidated summary
    \item \code{chunk.summaries} - Character vector with individual chunk summaries
  }
}
\description{
This function summarizes large volumes of text using a two-stage GPT approach:
(1) splits long text into chunks that fit within token limits and summarizes
each chunk, (2) combines chunk summaries into a final consolidated summary.
Handles token estimation and automatic chunking to prevent API limits from
being exceeded.
}
\examples{
\dontrun{
# Basic usage with event text
event.texts <- c("Event 1 description...", "Event 2 description...", ...)

summary.result <- getGptLongTextSummary(
  text.vec = event.texts,
  gpt.token = my_api_token,
  system.prompt.stage1 = "You are an expert analyst summarizing conflict events.",
  system.prompt.stage2 = "You are an expert analyst creating consolidated summaries."
)

# Access results
final.summary <- summary.result$final.summary
chunk.summaries <- summary.result$chunk.summaries

# Custom prompts and parameters
summary.result <- getGptLongTextSummary(
  text.vec = event.texts,
  gpt.token = my_api_token,
  system.prompt.stage1 = "Analyze these security events for key patterns.",
  user.prompt.stage1 = "Identify main actors and event types in:{text}",
  system.prompt.stage2 = "Synthesize these analyses into coherent overview.",
  user.prompt.stage2 = "Create final summary from:{text}",
  max.input.tokens = 100000,
  gpt.temperature = 0.1
)
}

}
